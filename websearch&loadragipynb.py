# -*- coding: utf-8 -*-
"""WebSearch&LoadRAGipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IoluMsr1jhwQO3EmKCqRK8sUrh_Cd_Ef
"""

!pip install --upgrade -q langchain langchain-community langchain-openai faiss-cpu beautifulsoup4 unstructured sentence-transformers

import os
from langchain_community.utilities import GoogleSerperAPIWrapper
from langchain.document_loaders import UnstructuredURLLoader, SeleniumURLLoader, WebBaseLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from google.colab import userdata

# Set your keys
os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY4')
os.environ["SERPER_API_KEY"] = userdata.get('SERPER_API_KEY')

base_urls = [
    "aalas.org", "jstor.org", "avmajournals.avma.org", "animalmicrobiome.biomedcentral.com",
    "irishvetjournal.biomedcentral.com", "bmcvetres.biomedcentral.com", "animaldiseases.biomedcentral.com",
    "actavetscand.biomedcentral.com", "sciendo.com", "canadianveterinarians.net", "parasite-journal.org",
    "sciencedirect.com", "microbiologyresearch.org", "jvas.in", "vaajournal.org", "frontiersin.org",
    "lp.thieme.de", "mdpi.com", "vetsci.org", "academic.oup.com", "journals.sagepub.com", "link.springer.com",
    "tandfonline.com", "onlinelibrary.wiley.com", "efsa.onlinelibrary.wiley.com",
    "resjournals.onlinelibrary.wiley.com", "beva.onlinelibrary.wiley.com", "bvajournals.onlinelibrary.wiley.com"
]

question = "How to prevent Rabies?"

combined_queries = [f"{url}: {question}" for url in base_urls]
combined_queries

from tqdm import tqdm

search = GoogleSerperAPIWrapper(k=10, type="search")

article_urls = set()
for query in tqdm(combined_queries):
    res = search.results(query)
    organic = res.get("organic", [])
    for item in organic[:10]:
        link = item.get("link")
        if any(base in link for base in base_urls):
            article_urls.add(link)
    # keep only top 2 matches
    # optionally break if threshold reached

urls = list(article_urls)[:20]  # limit if needed
loader = UnstructuredURLLoader(urls=urls)
docs = loader.load()
print(len(docs))
# fallback for JS-heavy: SeleniumURLLoader(urls=...)

urls

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = text_splitter.split_documents(docs)
len(chunks)

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(chunks, embeddings)

retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"lambda_mult": 0.3})

prompt = PromptTemplate.from_template(
    "Use the following context to answer the question:\n\n{context}\n\nQuestion: {question}"
)

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type_kwargs={"prompt": prompt}, return_source_documents=True)

answer = qa({"query": question})
print("Answer:", answer["result"])

for src in answer["source_documents"]:
    print("Source:", src.metadata.get("source"), src.page_content[:200], "...\n")





# Remove duplicates
article_url_list = list(set(article_url_list))

print(f"Total unique article URLs fetched: {len(article_url_list)}")

# Try WebBaseLoader or fallback to UnstructuredURLLoader
try:
    loader = WebBaseLoader(article_url_list)
    documents = loader.load()
except Exception as e:
    print(f"WebBaseLoader failed: {e}. Trying UnstructuredURLLoader.")
    loader = UnstructuredURLLoader(urls=article_url_list)
    documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
docs = text_splitter.split_documents(documents)

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(docs, embeddings)

retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"lambda_mult": 0.3}
)

# Prompt Template
template = """Use the following context to answer the question:
{context}

Question: {question}
"""

prompt = PromptTemplate.from_template(template)

llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt},
    return_source_documents=True
)

result = qa_chain(question)
print("Answer:\n", result['result'])





