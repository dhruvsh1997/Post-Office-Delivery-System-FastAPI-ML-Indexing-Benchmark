name: CI/CD — Deploy to EC2 (SQLite)

on:
  push:
    branches: [ "master" ]

jobs:
  test:
    name: Test / smoke
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Smoke import check
        run: |
          python - <<'PY'
          import importlib, sys
          for m in ["fastapi","sqlalchemy","pandas","joblib","sklearn"]:
              importlib.import_module(m)
          print("basic imports ok")
          PY

  deploy:
    name: Deploy to EC2
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install rsync + dvc (optional)
        run: |
          sudo apt-get update -y && sudo apt-get install -y rsync git
          python3 -m pip install --upgrade pip
          pip install "dvc[s3]"


      - name: SSH into EC2 and deploy
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: 3.111.114.159 #{{ secrets.EC2_HOST }}          # ec2-3-111-114-159.ap-south-1.compute.amazonaws.com
          username: ${{ secrets.EC2_USER }}      # ubuntu (likely)
          port: ${{ secrets.EC2_SSH_PORT }}      # 22
          key: ${{ secrets.EC2_SSH_KEY }}        # your AWS .pem contents
          debug: true
          script: |
            set -e
            whoami
            uname -a
            # go to app dir
            mkdir -p ${{ secrets.APP_DIR }}
            cd ${{ secrets.APP_DIR }}

            # pull latest code from origin/main
            # (assumes you cloned the repo here once — see Step 5)
            git fetch --all
            git reset --hard origin/main

            # python env
            if [ ! -d "venv" ]; then
              python3 -m venv venv
            fi
            . venv/bin/activate
            python -m pip install --upgrade pip
            pip install -r requirements.txt
            pip install "dvc[s3]"

            #EC2 instance setup
            mkdir -p ~/.aws
            echo "[default]" > ~/.aws/credentials
            echo "aws_access_key_id=${{ secrets.AWS_ACCESS_KEY_ID }}" >> ~/.aws/credentials
            echo "aws_secret_access_key=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> ~/.aws/credentials
            echo "[default]" > ~/.aws/config
            echo "region=ap-south-1" >> ~/.aws/config

            # echo "${{ secrets.EC2_SSH_KEY }}" > private_key.pem
            # chmod 600 private_key.pem

            # pull models/dataset via DVC from S3
            export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
            export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            export AWS_DEFAULT_REGION="${{ secrets.AWS_REGION }}"
            dvc pull -r ${{ secrets.DVC_REMOTE_NAME }}

            # restart the service
            sudo systemctl daemon-reload || true
            sudo systemctl restart postdelivery.service
            sudo systemctl status postdelivery.service --no-pager -n 100 || (sudo journalctl -u postdelivery.service -n 200; exit 1)
